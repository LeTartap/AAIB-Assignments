{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/aaib.PNG\" style=\"width:400px;height:250px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Today's Practice:\n",
    "\n",
    "1. Content-Related: **Implementing Supervised ML Models: LR, SVM, DT, RF, AdaBoost, and GB!**\n",
    "\\\n",
    "&nbsp;\n",
    "2. **Dataset:** We can see that there are 32 features (columns) and 119390 records (rows) in our dataset. Our main objective with this data is to predict if the **hotel booking** would be made by a customer, provided if they make a reservation within the constraints of out data.\n",
    "\\\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Commonly used libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# From ScikitLearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# loading dataset and chekcing its heads!\n",
    "data = pd.read_csv('datasets/hotel_bookings.csv')\n",
    "data.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We drop some columns right away because they either have very low variance or would not be support (make sense to be used)\n",
    "data.drop(inplace=True, axis=1, labels=['agent', 'company','hotel','reservation_status_date'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's check for any null values, if there are any...\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# As the focus of the practical is not on DPT, let's simply replace the null values with the mode.\n",
    "data.fillna(data.mode().iloc[0], inplace=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now we will separate the dependent and independent feature\n",
    "# The dependent variable is \"is canceled\", which tells us if a reservation was canceled (or not)\n",
    "# X = ?\n",
    "# y = ?\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Using onehotencoder for the categorical features!\n",
    "# ct = make_column_transformer(\n",
    "#     (OneHotEncoder(),['meal''distribution_channel','reservation_status','country','arrival_date_month','market_segment','deposit_type','customer_type', 'reserved_room_type','assigned_room_type']), remainder = 'passthrough')\n",
    "ct = make_column_transformer(\n",
    "    (OneHotEncoder(), ['meal', 'distribution_channel', 'reservation_status', 'country', 'arrival_date_month',\n",
    "                       'market_segment', 'deposit_type', 'customer_type', 'reserved_room_type', 'assigned_room_type'\n",
    "                      ]), remainder='passthrough')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Column Transformer is given the One Hot Encoder and the list of all categorical columns. \n",
    "# Now, we simply need to apply fit and transform to our independant variables.\n",
    "X = ct.fit_transform(X).toarray()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "X"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now, we split data between train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling & Dimensionality Reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that the number of features just went **from 28 to 256** very quickly. That is a very big number. The [curse of dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality) happens when a dataset has too many variables. It just means that our model will have to deal with too much unnecessary information, which will slow it down and make it less efficient.\n",
    "\n",
    "We use methods called [Dimensionality Reduction](https://en.wikipedia.org/wiki/Dimensionality_Reduction) to avoid the curse of dimensionality. PCA, or [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis), is one of the most popular ones. PCA has however one small requirement: the data it is used on must have a sandar scale. Which we do in the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scaling the data (Train and Test)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"X_train ---------->\\n\", X_train, \"\\nX_test -------->\\n\", X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Implementing PCA - To reduce Dimensionality \n",
    "pca = PCA(n_components = 50)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance\n",
    "# The number of components that we are asking to be selected is 50. IN practice you do with \"None\", check EV, \n",
    "# then select a threshold and compare the EV."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - LR"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=1000, solver = 'lbfgs')\n",
    "classifier.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how our model performs on the test data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's check how our model performs on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy of our model, the simplest way is to construct a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Confusion matrix (CM)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Accuracy Score\n",
    "# ac = accuracy_score(y_train, y_pred)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf_svm = svm.SVC(max_iter=1000, gamma='scale', kernel = \"rbf\", random_state=0)\n",
    "clf_svm.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf_svm.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - DT"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf_tree = tree.DecisionTreeClassifier(max_depth=5, criterion = \"gini\", min_samples_split=100,\n",
    "                                       min_samples_leaf= 30, random_state=0)\n",
    "clf_tree.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf_tree.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - RF"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=30, max_depth=5, random_state=0)\n",
    "clf_rf.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf_rf.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - AB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf_ab = AdaBoostClassifier(n_estimators=100, learning_rate=1, random_state=0)\n",
    "clf_ab.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf_ab.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Implementation - GB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clf_gb = GradientBoostingClassifier(n_estimators=30, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "clf_gb.fit(X_train, y_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y_pred = clf_gb.predict(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Voting Classifier"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log_reg', classifier),\n",
    "        ('svm_clf', clf_svm),\n",
    "        ('dt_clf', clf_tree),\n",
    "        ('rf_clf', clf_rf),\n",
    "        ('ada_clf', clf_svm),\n",
    "        ('gb_clf', clf_svm)\n",
    "    ],\n",
    "    voting='soft'  # Can be 'soft' for averaging probabilities\n",
    ")\n",
    "    \n",
    "# Train and evaluate the Voting Classifier\n",
    "accuracy_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "f1_scores = cross_val_score(voting_clf, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f'Voting Classifier Accuracy: {accuracy_scores.mean():.4f}')\n",
    "print(f'Voting Classifier F1-Score: {f1_scores.mean():.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:08:46.161963Z",
     "start_time": "2024-06-29T23:08:46.148340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#fit all models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classifier = LogisticRegression(random_state=0, max_iter=1000, solver='lbfgs')\n",
    "\n",
    "\n",
    "clf_svm = SVC(max_iter=1000, gamma='scale', kernel='rbf', random_state=0, probability=True)\n",
    "\n",
    "\n",
    "clf_tree = DecisionTreeClassifier(max_depth=5, criterion='gini', min_samples_split=100, min_samples_leaf=30, random_state=0)\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=30, max_depth=5, random_state=0)\n",
    "\n",
    "\n",
    "clf_ab = AdaBoostClassifier(n_estimators=100, learning_rate=1, random_state=0)\n",
    "\n",
    "\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=30, learning_rate=0.1, max_depth=1, random_state=0)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:12:21.078368Z",
     "start_time": "2024-06-29T23:09:27.579035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from joblib import parallel_backend\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combine models into a Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('log_reg', classifier),\n",
    "        ('svm_clf', clf_svm),\n",
    "        ('dt_clf', clf_tree),\n",
    "        ('rf_clf', clf_rf),\n",
    "        ('ada_clf', clf_ab),\n",
    "        ('gb_clf', clf_gb)\n",
    "    ],\n",
    "    voting='soft'  # Use 'hard' for hard voting\n",
    ")\n",
    "\n",
    "# Use parallel processing if possible\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the Voting Classifier\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the Voting Classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Voting Classifier Accuracy: {accuracy:.4f}')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sklearn\\svm\\_base.py:258: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Accuracy: 0.9964\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## References:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Dataset from Kaggle](https://www.kaggle.com/datasets/ahsan81/hotel-reservations-classification-dataset)\n",
    "- [Hotel Booking (Logistic Regression) by Amit Sharma](https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
